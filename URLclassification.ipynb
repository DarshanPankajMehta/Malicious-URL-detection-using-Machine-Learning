{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "URLclassification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmbTKdLwtr9d"
      },
      "source": [
        "#Importing Necessary Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GaLGM6EsgrG"
      },
      "source": [
        "allurlscsv = pd.read_csv(\"/content/data.csv\",',',error_bad_lines=False)\t#reading file\n",
        "allurlsdata = pd.DataFrame(allurlscsv)\t#converting to a dataframe\n",
        "allurlsdata = np.array(allurlsdata)\t#converting it into an array\n",
        "rd.shuffle(allurlsdata)\t#shuffling\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYN6VIAavhTC"
      },
      "source": [
        "#Defining Function to tokenize URLs\n",
        "def getTokens(input):\n",
        "\ttokensBySlash = str(input.encode('utf-8')).split('/')\t#get tokens after splitting by slash\n",
        "\tallTokens = []\n",
        "\tfor i in tokensBySlash:\n",
        "\t\ttokens = str(i).split('-')\t#get tokens after splitting by dash\n",
        "\t\ttokensByDot = []\n",
        "\t\tfor j in range(0,len(tokens)):\n",
        "\t\t\ttempTokens = str(tokens[j]).split('.')\t#get tokens after splitting by dot\n",
        "\t\t\ttokensByDot = tokensByDot + tempTokens\n",
        "\t\tallTokens = allTokens + tokens + tokensByDot\n",
        "\tallTokens = list(set(allTokens))\t#remove redundant tokens\n",
        "\tif 'com' in allTokens:\n",
        "\t\tallTokens.remove('com')\t#removing .com since it occurs a lot of times and it should not be included in our features\n",
        "\treturn allTokens"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlC0D6NjvBV4"
      },
      "source": [
        "y = [d[1] for d in allurlsdata]\t#all labels \n",
        "corpus = [d[0] for d in allurlsdata]\t#all urls corresponding to a label (either good or bad)\n",
        "vectorizer = TfidfVectorizer(tokenizer=getTokens)\t#get a vector for each url but use our customized tokenizer\n",
        "X = vectorizer.fit_transform(corpus)\t#get the X vector"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFrGKlR2vxuL"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg2RR4QqzCkm"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\t"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIkIE8mgwBAQ"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuYhP1rezAR-",
        "outputId": "fd048776-777d-4aad-9886-ae4d373edfba"
      },
      "source": [
        "lgs = LogisticRegression()\t#using logistic regression\n",
        "lgs.fit(X_train, y_train)\n",
        "print(lgs.score(X_test, y_test))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9834965088768778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lamnqKC0whhi",
        "outputId": "eb357ee2-15b9-480b-9a3b-69daa942be6b"
      },
      "source": [
        "X_predict = ['www.radsport-voggel.de/wp-admin/includes/log.exe','printmedianet.com/','ahrenhei.without-transfer.ru/nethost.exe','www.itidea.it/centroesteticosothys/img/_notes/gum.exe']\n",
        "\n",
        "X_predict = vectorizer.transform(X_predict)\n",
        "\n",
        "y_Predict = lgs.predict(X_predict)\n",
        "\n",
        "print(y_Predict)\t#printing predicted values"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bad' 'good' 'bad' 'bad']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ-VNgZN0TUu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}